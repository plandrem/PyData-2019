{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Basics\n",
    "\n",
    "### a.k.a. \"Stuff You've Seen Before\"\n",
    "\n",
    "Assuming you've drunk the Kool-Aid that linear algebra is useful, let's start dusting off some of those neurons from your introductory classes. In this notebook, I'll focus on visualizations and applications for these topics:\n",
    "\n",
    "* Rank\n",
    "* Nullspace\n",
    "* Determinant & Singularity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.194122Z",
     "start_time": "2019-11-04T04:37:08.385935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Render MPL figures within notebook cells\n",
    "%matplotlib inline\n",
    "\n",
    "# Import python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.202091Z",
     "start_time": "2019-11-04T04:37:09.197194Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure some defaults for plots\n",
    "rcParams['font.size'] = 16\n",
    "rcParams['figure.figsize'] = (10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.260035Z",
     "start_time": "2019-11-04T04:37:09.205186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set Numpy's random number generator so the same results are produced each time the notebook is run\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sensor Interpretation of a Linear System\n",
    "\n",
    "It can be helpful to imagine $y=Ax$ as the following:\n",
    "\n",
    "* $x$ describes the outputs of $n$ transmitters\n",
    "* $y$ contains $m$ sensor measurements\n",
    "* $a_{i,j}$ is the impact of transmitter $j$ on sensor $i$\n",
    "\n",
    "<img src='img/sensor_interp.png' style='height: 200px'>\n",
    "\n",
    "With this picture, you can start to think of columns as the \"fingerprints\" of the inputs - if you crank up the transmission power from $x_3$, then $y$ starts to look more like $a_3$. Another perspective is that the vector $x$ is a recipe for mixture of columns of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank\n",
    "\n",
    "The **rank** of a matrix is a number that tells you the size of the largest group of rows or columns of $A$ that form a [linearly independent](https://en.wikipedia.org/wiki/Linear_independence) set.\n",
    "\n",
    "Consider the following matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.279271Z",
     "start_time": "2019-11-04T04:37:09.265044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix whose rows form a linearly-independent set\n",
    "A = np.eye(3)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how hard I want to, there is no way that I can mix the first two rows of $A$ by scaling and adding them that will result in the third row. Thus, the rank of $A$ is 3, which Numpy cheerfully tells us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.295786Z",
     "start_time": "2019-11-04T04:37:09.279271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good property to remember is that $\\text{rank}(A) \\le \\min\\{m, n\\}$. As soon as we add a new row, we are guaranteed that it will be a linear combination of the previous rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.312709Z",
     "start_time": "2019-11-04T04:37:09.296783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row 3 = (Row 1) * 2 + (Row 2) + (Row 3)\n",
    "\n",
    "B = np.array([[1, 0, 0],\n",
    "              [0, 1, 0],\n",
    "              [0, 0, 1],\n",
    "              [2, 1, 1]])\n",
    "\n",
    "np.linalg.matrix_rank(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.325497Z",
     "start_time": "2019-11-04T04:37:09.316715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transposing a matrix (flipping rows and columns) preserves rank\n",
    "np.linalg.matrix_rank(B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\text{rank}(A) = \\min\\{m, n\\}$, we say that $A$ is **full rank**. \n",
    "\n",
    "**Question:** what is the rank of the matrix $A$ with columns $[a_1 \\; a_2 \\; a_3]$, shown below?\n",
    "\n",
    "<img src='img/independence.png' style='height: 200px'>\n",
    "\n",
    "First, notice that $A \\in \\mathbb{R}^{2 \\times 3}$. Even though the set of vectors is not independent, the rank is still full (2) because at least 2 of the vectors are not colinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application: Compression + Efficiency\n",
    "\n",
    "As soon as there is some notion of redundant information, one can start thinking about applications in compression. Take the highly contrived but illustrative example of storing a matrix with 1,000,000 rows and 2 columns, where the 2nd column is exactly double the first column. That is,\n",
    "\n",
    "<center>\n",
    "$\n",
    "A =\n",
    "  \\begin{bmatrix}\n",
    "    a_{1,1} & 2a_{1,1} \\\\\n",
    "    a_{2,1} & 2a_{2,1} \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{n,1} & 2a_{n,1} \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "</center>\n",
    "\n",
    "This would be a silly thing to do, when one could immediately save half of the memory by storing only the first column, and remembering to double the value whenever we need to index into the 2nd column. We can achieve this by representing $A$ as the following:\n",
    "\n",
    "<center>\n",
    "$\n",
    "A =\n",
    "  \\begin{bmatrix}\n",
    "    a_{1,1} & 2a_{1,1} \\\\\n",
    "    a_{2,1} & 2a_{2,1} \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{n,1} & 2a_{n,1} \\\\\n",
    "  \\end{bmatrix}\n",
    "=\n",
    "  \\begin{bmatrix}\n",
    "    a_{1,1} \\\\\n",
    "    a_{2,1} \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{n,1} \\\\\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}\n",
    "  1 & 2\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea generalizes to matrices of any shape:\n",
    "\n",
    "> A matrix $A$ with rank $r$ can be factored into matrices $Q \\in \\mathbb{R}^{m \\times r}$ and $R \\in \\mathbb{R}^{r \\times n}$\n",
    "\n",
    "<img src='img\\qr_factorization.png' style='height: 200px'>\n",
    "\n",
    "Our lovely Mathematician friends have given us multiple algorithms that will produce these smaller matrices for us (see [QR decomposition](https://en.wikipedia.org/wiki/QR_decomposition)). We'll see one such algorithm in a later chapter.\n",
    "\n",
    "Armed with this fact, we can quickly calculate how many numbers we have to store for the original matrix versus the factorized matrices:\n",
    "\n",
    "$\\;\\;$ Size of $A = mn$\n",
    "\n",
    "$\\;\\;$ Size of $Q$ + Size of $R = mr + rn = r(m+n)$\n",
    "\n",
    "As soon as $r$ becomes appreciably smaller than $m$ and $n$, this trick can save a lot of space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.341092Z",
     "start_time": "2019-11-04T04:37:09.330100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 1000\n",
    "n = 1000\n",
    "r = 10\n",
    "\n",
    "# Storage cost of A\n",
    "m*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.354373Z",
     "start_time": "2019-11-04T04:37:09.345070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storage cost of QR\n",
    "m*r + r*n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiplication Efficiency**\n",
    "\n",
    "Amusingly, the math is identical when you estimate how many floating-point operations (FLOPs) it takes to compute $Ax = Q(Rx)$\n",
    "\n",
    "$\\;\\;$ FLOPs to compute $Ax$ = (# rows) x FLOPs to compute ($\\tilde{a}^\\mathsf{T}x)$ $\\sim O(mn)$\n",
    "\n",
    "$\\;\\;$ FLOPs to compute $QRx\\sim O(mr + rn) = O(r(m+n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nullspace\n",
    "\n",
    "\"The Nullspace\" is a term that haunted me from my first linear algebra class. I remember thinking it sounded cool, but I had no grasp of what it really meant. I think the simplest way of understanding the idea is this: every matrix has a nullspace, which is a list of vectors. If you multiply your matrix $A$ by a vector $z$ and the result is the zero vector, then you put $z$ in the list.\n",
    "\n",
    "> The nullspace of $A$ is the set of vectors, $z$, such that $Az = 0$\n",
    "\n",
    "If we were to express this in code, `A.nullspace()` would return a list of vectors. This list would be infinitely long, but one can return a list of vectors that can be used to reconstruct any vector in the nullspace via linear combinations (we would call this finite set a **basis** for the nullspace). There isn't a direct way to return the nullspace of $A$ with Numpy, but we will cover how to do this in a later chapter (see Ch 4 - Singular Value Decomposition).\n",
    "\n",
    "The **key idea** about vectors in the nullspace of $A$ is that they represent redundancy or flexibility in the system:\n",
    "\n",
    "$A(x + z) = Ax + Az = Ax + 0 = Ax$\n",
    "\n",
    "We can add any vector from the nullspace \"for free.\" Visually, if we plot the points $x$ where $Ax$ equals some constant $b$, then any vector that is parallel to the line is in the nullspace of $A$:\n",
    "\n",
    "<img src='img\\nullspace.png' style='height: 200px'>\n",
    "\n",
    "This is great if, for instance, we have $y=Ax$ where $y$ is a target we are trying to achieve. Lots of vectors in the nullspace means we have options to choose from for our input, and we can optimize on some other criteria.\n",
    "\n",
    "However, if you recall our transmitter/receiver analogy from above, having vectors in the nullspace of our matrix can be a very bad thing! Imagine you are trying to reconstruct what your transmitters were sending from the sensor measurements you detect. If there are multiple ways to transmit signals that produce the same received measurements, **you can never know which signals were sent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singularity\n",
    "\n",
    "This last idea, that you can't \"undo\" the transformation from multiplying $x$ by $A$, is mathematically expressed by saying that $A$ is not invertible. Precisely, there is no matrix $B$ such that \n",
    "\n",
    "<center>\n",
    "    $x = B(Ax)$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea is also expressed by saying that \"$A$ has no left inverse\". In the special case where $A$ is square, you will encounter people using the term **singular** to mean a matrix which has no inverse. As best I can find, the term singular refers to an (incorrect) understanding that most square matrices are invertible, and so non-invertible matrices are special. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Determinant\n",
    "\n",
    "Another abstract concept you would undoubtedly find in a beginning linear algebra class is **the determinant** of a matrix. You probably were drilled at length on using [Cramer's Rule](https://en.wikipedia.org/wiki/Cramer%27s_rule) to calculate the determinant, and that was probably all you would have done with it.\n",
    "\n",
    "The determinant is connected to all of the previous topics in this section, which I have grouped together because they all indicate whether or not a matrix operation can be undone. In applied terms, whether or not an estimation problem has a unique solution, or if a design problem has multiple choices.\n",
    "\n",
    "The determinant is a number that **determines** if a square matrix is singular. That's where the name comes from. If $\\det(A)=0$, then $A$ has no inverse.\n",
    "\n",
    "Ok great. Why?\n",
    "\n",
    "There is a great visual interpretation - we'll work in a 3-dimensional space so that we can draw it, but this extends to any number of dimensions. Suppose we have a cube with volume 1. Applying the matrix $A$ to the vectors which define the points on the boundary of the cube results in a parallelopiped with volume equal to the determinant of $A$:\n",
    "\n",
    "<img src='img/determinant_1.png' style='height: 200px'>\n",
    "\n",
    "If the determinant of $A$ is 0, the resulting parallelopiped has volume 0, which implies at least one dimension of the cube is flattened:\n",
    "\n",
    "<img src='img/determinant_2.png' style='height: 200px'>\n",
    "\n",
    "In the picture above, any information in the vertical direction is lost - you can't unflatten the shape because you don't know how high to stretch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can demonstrate this volume concept in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.369929Z",
     "start_time": "2019-11-04T04:37:09.359000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a 3d unit cube\n",
    "C = np.eye(3)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.385231Z",
     "start_time": "2019-11-04T04:37:09.373653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 2],\n",
       "       [1, 4, 4],\n",
       "       [4, 4, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a transformation matrix\n",
    "A = np.random.randint(low=1, high=5, size=(3, 3))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.400901Z",
     "start_time": "2019-11-04T04:37:09.389461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 4., 2.],\n",
       "       [1., 4., 4.],\n",
       "       [4., 4., 2.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the unit cube vectors correspond to an Identity matrix, the output of the transform\n",
    "# is the same as the transformation matrix\n",
    "A @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.417521Z",
     "start_time": "2019-11-04T04:37:09.404196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.000000000000004"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The volume of the transformed cube is given by the determinant\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T04:37:09.434914Z",
     "start_time": "2019-11-04T04:37:09.420512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we make two of the columns of A identical, this will have the effect of \n",
    "# Making the parallelopiped effectively 2-dimensional. The determinant will be\n",
    "# zero to reflect this.\n",
    "A_flat = A\n",
    "A_flat[:, 2] = A[:, 1]\n",
    "np.linalg.det(A_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unification\n",
    "\n",
    "You may have noticed just now that, to create a matrix with a zero determinant, I made one column of A equal to another column. This dropped the rank of $A$. This was not a coincidence. In fact, the rank of $A$ can also be interpreted as the number of dimensions in the accessible output space (the **range**) of $A$ - if this number is less than the number of dimensions of $x$, then some kind of geometric flattening is going to happen and the determinant will be zero. \n",
    "\n",
    "At the same time, removing a dimension from the range of $A$ **adds** a dimension to the nullspace of $A$! There is a handy property:\n",
    "\n",
    "> $\\text{Rank}(A) + \\text{dim Null}(A) = n$\n",
    "\n",
    "All of the topics in this section are intimately connected, each communicating whether or not a matrix is invertible. To summarize, the following statements are equivalent:\n",
    "\n",
    "- $A$ is full rank\n",
    "- $A$ has only the zero vector in its nullspace\n",
    "- the determinant of $A$ is non-zero\n",
    "- $A$ has a left inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
